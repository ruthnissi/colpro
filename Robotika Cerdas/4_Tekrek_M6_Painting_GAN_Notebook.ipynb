{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVnF24NFcuQ6"
   },
   "source": [
    "## **Mount Google Drive to Store Files and Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTnZed8a1yaq"
   },
   "outputs": [],
   "source": [
    "# Berikut adalah link yang dapat Anda set dalam kode program Anda. Anda dapat mendownload dataset yang Anda butuhkan melalui link berikut:\n",
    "# Link 1000 images: https://www.dropbox.com/s/c0yfe4bpt0orb0m/paintings1k.zip?dl=1\n",
    "# Link 5000 images: https://www.dropbox.com/s/yhu8v2yhft70doh/paintings5k.zip?dl=1\n",
    "# Link 10000 images: https://www.dropbox.com/s/16jrkfrdm0c543q/paintings15k.zip?dl=1\n",
    "\n",
    "# File yang terdownload akan dalam format .zip. Silakan disimpan di direktori Anda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzVT_cB7cZFp",
    "outputId": "d9417c9f-3fa9-4c13-8586-4e6a7b15c1c3"
   },
   "outputs": [],
   "source": [
    "# Gunakan fungsi ini jika Anda menjalankan kode program pada google collab dan menggunakan google drive untuk menyimpan file.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Jika Anda menjalankan pada komputer Anda, abaikan blok program ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJp-D51g0IDd"
   },
   "source": [
    "## **1) Importing Python Packages for GAN**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1k5mFBuzzl2a"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D, Dense, Conv2DTranspose\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "!mkdir generated_images resized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoRqPt1DwtD_"
   },
   "outputs": [],
   "source": [
    "# Unzip the-zip-file -d name-of-destination-folder\n",
    "# the-zip-file: path dari folder sumber data yang akan Anda gunakan.\n",
    "# name-of-destination-folder: nama folder yang tempat hasil file yang akan di unzip disimpan.\n",
    "# Contoh: !unzip /content/drive/MyDrive/paintings1k.zip -d 5kImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHst9_aeoTNd",
    "outputId": "8456f731-1d5b-4e07-eb8e-72fdb1202002"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/paintings1k.zip -d 5kImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRWx5D09dX3p"
   },
   "outputs": [],
   "source": [
    "# Isi bagian didalam tanda \"\" dengan alamat path dari image yang akan Anda gunakan.\n",
    "# Hint: klik kanan pada folder yang Anda tuju, kemudian pilih copy-path.\n",
    "# Contoh: /content/drive/5kImage\n",
    "\n",
    "images_path = \"<...>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaoY5WTbi4dJ"
   },
   "source": [
    "## **Resizing Data to match Neural Network Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUJtmq0gzkSx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# from PIL import Image\n",
    "import cv2\n",
    "reshape_size = (64,64)\n",
    "\n",
    "i = 0\n",
    "for image in os.listdir(images_path):\n",
    "  # print(image)\n",
    "  img = cv2.imread(images_path + image)\n",
    "  img = cv2.resize(img, reshape_size)\n",
    "  cv2.imwrite(\"resized_images/%d.png\" % i,img)\n",
    "  # print(img.shape)\n",
    "  i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr-eZOzg0X79"
   },
   "source": [
    "## **2) Parameters for Neural Networks & Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RThZMDruz9cB"
   },
   "outputs": [],
   "source": [
    "img_width = 64\n",
    "img_height = 64\n",
    "channels = 3\n",
    "img_shape = (img_width, img_height, channels)\n",
    "latent_dim = 100\n",
    "adam = Adam(learning_rate=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3bcJZZg0cqy"
   },
   "source": [
    "## **3) Building Generator**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "NdiqZpri0iQh",
    "outputId": "04fa1464-222e-41e9-e3e0-37d64d55a848"
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256 * 8* 8, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((8,8,256)))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bt6QsJCW0mcI"
   },
   "source": [
    "## **4) Building Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "V2JzEAPv0lKt",
    "outputId": "d0c47649-b4bc-44d0-a545-756be118c71f"
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), padding='same', input_shape=img_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding='same', ))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbcKcKmA0q2S"
   },
   "source": [
    "## **5) Connecting Neural Networks to build GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0Ue3TEd0xLy"
   },
   "outputs": [],
   "source": [
    "GAN = Sequential()\n",
    "discriminator.trainable = False\n",
    "GAN.add(generator)\n",
    "GAN.add(discriminator)\n",
    "\n",
    "GAN.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "EPqU8dZDaQmE",
    "outputId": "52c528a6-a64a-4fd8-9491-7c93529542f0"
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "1EDrytlPwRoz",
    "outputId": "1ae5ffe5-5891-40fb-ea86-529d02c12178"
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WaNhBDwRwTG"
   },
   "source": [
    "## **6) Outputting Images**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQEJ0WbjRppy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import imageio\n",
    "import PIL\n",
    "\n",
    "save_name = 0.00000000\n",
    "\n",
    "def save_imgs(epoch):\n",
    "    r, c = 4, 4\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    global save_name\n",
    "    save_name += 0.00000001\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = (gen_imgs + 1) / 2.0\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"currentgeneration.png\")\n",
    "    fig.savefig(\"generated_images/%.8f.png\" % save_name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE57Lk5V0xs2"
   },
   "source": [
    "## **7) Training GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mou4S86K2vhe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 100  # Define latent dimension\n",
    "\n",
    "def train(epochs, batch_size=32, save_interval=200):\n",
    "    (X_train, _), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
    "    X_train = X_train / 127.5 - 1.0  # Normalize to [-1, 1]\n",
    "\n",
    "    bat_per_epo = int(X_train.shape[0] / batch_size)\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fakes = np.zeros((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            # Train discriminator\n",
    "            d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_imgs, fakes)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            g_loss = GAN.train_on_batch(noise, valid)\n",
    "\n",
    "            print(\"Epoch: %d Batch: %d [D loss: %f, acc: %.2f%%] [G loss: %f]\" %\n",
    "                  (epoch, j, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "        if epoch % save_interval == 0:\n",
    "            generator.save(f\"generator_epoch_{epoch}.h5\")  # Save model at intervals\n",
    "\n",
    "train(30000, batch_size=32, save_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kT7_Wk-TS_n2"
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (16, latent_dim))\n",
    "gen_imgs = generator.predict(noise)\n",
    "gen_imgs = (gen_imgs + 1) / 2.0\n",
    "# plt.imshow(gen_imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbWAZ1v_TdJd"
   },
   "outputs": [],
   "source": [
    "plt.imshow(gen_imgs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8YtpQpkRvRI"
   },
   "outputs": [],
   "source": [
    "generator.save_weights(\"/content/drive/MyDrive/models/generator1hour.h5\")\n",
    "discriminator.save_weights(\"/content/drive/MyDrive/models/discriminator1hour.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "po-jSQoN1Azl"
   },
   "source": [
    "### **8) Making GIF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPShgQpg1EMy"
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "# def display_image(epoch_no):\n",
    "#   return PIL.Image.open('generated_images/%.8f.png'.format(epoch_no))\n",
    "\n",
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('generated_images/*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "  if filenames:  # Check if filenames is not empty\n",
    "    image = imageio.imread(filenames[-1])\n",
    "    writer.append_data(image)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
